{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4dabd3d",
   "metadata": {},
   "source": [
    "# <h1 style=\"text-align:center; color:blue;\">Regression algorithms part 2</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21d4b7fa",
   "metadata": {},
   "source": [
    "**We use the same data as part 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9048d4ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train: (396, 5)\n",
      "Shape of X_test: (99, 5)\n",
      "Shape of y_train: (396,)\n",
      "Shape of y_test: (99,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import numpy.typing as npt\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# 1. Generate synthetic regression dataset with both numerical and categorical features\n",
    "np.random.seed(42)\n",
    "n_samples: int = 500\n",
    "\n",
    "# Numerical features\n",
    "age: npt.NDArray[np.int64] = np.random.randint(18, 70, size=n_samples)\n",
    "salary: npt.NDArray[np.float64] = np.random.normal(50000, 15000, size=n_samples)\n",
    "experience: npt.NDArray[np.int64] = np.random.randint(0, 40, size=n_samples)\n",
    "\n",
    "# Categorical features\n",
    "departments: npt.NDArray[np.str_] = np.random.choice(['HR', 'Engineering', 'Marketing', 'Sales'], size=n_samples)\n",
    "education: npt.NDArray[np.str_] = np.random.choice(['Bachelors', 'Masters', 'PhD'], size=n_samples)\n",
    "\n",
    "# Target variable (continuous)\n",
    "target: npt.NDArray[np.float64] = (\n",
    "    20000 + age * 150 + experience * 300 +\n",
    "    (departments == 'Engineering') * 10000 +\n",
    "    (education == 'PhD') * 5000 +\n",
    "    np.random.normal(0, 5000, size=n_samples)\n",
    ")\n",
    "\n",
    "# Create DataFrame\n",
    "df: pd.DataFrame = pd.DataFrame({\n",
    "    'Age': age,\n",
    "    'Salary': salary,\n",
    "    'Experience': experience,\n",
    "    'Department': departments,\n",
    "    'Education': education,\n",
    "    'Target': target\n",
    "})\n",
    "\n",
    "# 3.2 Outlier removal (using IQR for numerical columns)\n",
    "def remove_outliers_iqr(data : pd.DataFrame, column : str) -> pd.DataFrame:\n",
    "    Q1: float = data[column].quantile(0.25)\n",
    "    Q3: float = data[column].quantile(0.75)\n",
    "    IQR: float = Q3 - Q1\n",
    "    not_outliers: pd.DataFrame = data[(data[column] > (Q1 - 1.5 * IQR)) & (data[column] < (Q3 + 1.5 * IQR))]\n",
    "    return not_outliers\n",
    "\n",
    "outliers_cols : list[str] = ['Salary', 'Target']\n",
    "\n",
    "for col in outliers_cols:\n",
    "    df = remove_outliers_iqr(df, col)\n",
    "\n",
    "# 4. Encode categorical data and scale numerical features\n",
    "\n",
    "# Splitting categorical and numerical\n",
    "categorical_df: pd.DataFrame = df.select_dtypes('object')\n",
    "numerical_df: pd.DataFrame = df.select_dtypes('number')\n",
    "\n",
    "# Getting the corresponding columns\n",
    "categorical_cols: list[str] = categorical_df.columns.to_list()\n",
    "numerical_cols: list[str] = numerical_df.columns.to_list()\n",
    "\n",
    "# Importing the functions\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "\n",
    "# Encoding\n",
    "le: LabelEncoder = LabelEncoder()\n",
    "\n",
    "for col in categorical_cols:\n",
    "    df[col] = le.fit_transform(df[col])\n",
    "\n",
    "# Scaling\n",
    "scaler: StandardScaler = StandardScaler()\n",
    "\n",
    "for col in numerical_cols:\n",
    "    df[[col]] = scaler.fit_transform(df[[col]])\n",
    "\n",
    "# 5. Split the data into train and test sets\n",
    "\n",
    "# Importing the function\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Getting X and y\n",
    "\n",
    "X: pd.DataFrame = df.drop('Target', axis=1)\n",
    "y: pd.Series = df['Target']\n",
    "\n",
    "# Splitting\n",
    "X_train: pd.DataFrame\n",
    "X_test: pd.DataFrame\n",
    "y_train: pd.Series\n",
    "y_test: pd.Series\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(\"Shape of X_train:\", X_train.shape)\n",
    "print(\"Shape of X_test:\", X_test.shape)\n",
    "print(\"Shape of y_train:\", y_train.shape)\n",
    "print(\"Shape of y_test:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b179443f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.base import BaseEstimator\n",
    "from typing import Union\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a91c89ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(model: BaseEstimator,\n",
    "                       X_train: pd.DataFrame,\n",
    "                       y_train: pd.Series,\n",
    "                       X_test: pd.DataFrame,\n",
    "                       y_test: pd.Series) -> dict[str, Union[float, np.float64]]:\n",
    "    \"\"\"\n",
    "    Trains the given regression model and returns accuracy (R^2) and error (RMSE) for both train and test sets.\n",
    "    \"\"\"\n",
    "\n",
    "    # Fit the model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predictions\n",
    "    y_train_pred: npt.NDArray[np.float64] = model.predict(X_train)\n",
    "    y_test_pred: npt.NDArray[np.float64] = model.predict(X_test)\n",
    "    \n",
    "    # Accuracy (R^2)\n",
    "    train_r2: float = model.score(X_train, y_train)\n",
    "    test_r2: float = model.score(X_test, y_test)\n",
    "    \n",
    "    # Error (RMSE)\n",
    "    train_rmse: np.float64 = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
    "    test_rmse: np.float64 = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "    \n",
    "    results: dict[str, Union[float, np.float64]] = {\n",
    "        \"train_r2\": train_r2,\n",
    "        \"test_r2\": test_r2,\n",
    "        \"train_rmse\": train_rmse,\n",
    "        \"test_rmse\": test_rmse\n",
    "    }\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa9c0d0a",
   "metadata": {},
   "source": [
    "### 6- Support vector Regression (SVR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c9d00198",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train_r2': 0.5034237800990844,\n",
       " 'test_r2': 0.4208244085427282,\n",
       " 'train_rmse': np.float64(0.7131576778295406),\n",
       " 'test_rmse': np.float64(0.7201679580506448)}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVR\n",
    "\n",
    "svr_linear:BaseEstimator = LinearSVR()\n",
    "\n",
    "train_and_evaluate(model= svr_linear,\n",
    "                   X_train= X_train,\n",
    "                   y_train= y_train,\n",
    "                   X_test= X_test,\n",
    "                   y_test= y_test\n",
    "                   )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d40c15e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train_r2': 0.6688016148637084,\n",
       " 'test_r2': 0.5108147574739019,\n",
       " 'train_rmse': np.float64(0.5824205744628743),\n",
       " 'test_rmse': np.float64(0.661858792696883)}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "\n",
    "svr_kernel_rbf: BaseEstimator = SVR()\n",
    "\n",
    "train_and_evaluate(model= svr_kernel_rbf,\n",
    "                   X_train= X_train,\n",
    "                   y_train= y_train,\n",
    "                   X_test= X_test,\n",
    "                   y_test= y_test\n",
    "                   )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e5369b6",
   "metadata": {},
   "source": [
    "### 7- Decision Tree Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "430458d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train_r2': 1.0,\n",
       " 'test_r2': -0.18541812475085195,\n",
       " 'train_rmse': np.float64(0.0),\n",
       " 'test_rmse': np.float64(1.0303017817568225)}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "DTR: BaseEstimator = DecisionTreeRegressor()\n",
    "\n",
    "train_and_evaluate(model= DTR,\n",
    "                   X_train= X_train,\n",
    "                   y_train= y_train,\n",
    "                   X_test= X_test,\n",
    "                   y_test= y_test\n",
    "                   )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1560669",
   "metadata": {},
   "source": [
    "**Note the overfitting**\n",
    "\n",
    "**Fixing this is not in the course content**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a5b963",
   "metadata": {},
   "source": [
    "### 8- Random Forest Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e73f10b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train_r2': 0.9433971470980185,\n",
       " 'test_r2': 0.4290319231259069,\n",
       " 'train_rmse': np.float64(0.24077520629005447),\n",
       " 'test_rmse': np.float64(0.7150469901620776)}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "RFR: BaseEstimator = RandomForestRegressor()\n",
    "\n",
    "train_and_evaluate(model= RFR,\n",
    "                   X_train= X_train,\n",
    "                   y_train= y_train,\n",
    "                   X_test= X_test,\n",
    "                   y_test= y_test\n",
    "                   )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffbfbe70",
   "metadata": {},
   "source": [
    "### 9- K-Nearest Neighbors Regression (KNN Regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b533e432",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train_r2': 0.6779505998597154,\n",
       " 'test_r2': 0.43197131833104985,\n",
       " 'train_rmse': np.float64(0.5743198810300899),\n",
       " 'test_rmse': np.float64(0.7132040519695594)}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "KNR:BaseEstimator = KNeighborsRegressor()\n",
    "\n",
    "train_and_evaluate(model= KNR,\n",
    "                   X_train= X_train,\n",
    "                   y_train= y_train,\n",
    "                   X_test= X_test,\n",
    "                   y_test= y_test\n",
    "                   )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e51bb6",
   "metadata": {},
   "source": [
    "### 10- - Bayesian Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0d0195c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train_r2': 0.5063930709411979,\n",
       " 'test_r2': 0.43595656322585663,\n",
       " 'train_rmse': np.float64(0.7110223081753506),\n",
       " 'test_rmse': np.float64(0.710697756257328)}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import BayesianRidge\n",
    "\n",
    "BR: BaseEstimator = BayesianRidge()\n",
    "\n",
    "train_and_evaluate(model= BR,\n",
    "                   X_train= X_train,\n",
    "                   y_train= y_train,\n",
    "                   X_test= X_test,\n",
    "                   y_test= y_test\n",
    "                   )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f6f19d9",
   "metadata": {},
   "source": [
    "**Note: bagging is not in the content**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a92ce6b4",
   "metadata": {},
   "source": [
    "## Boosting algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b5af5f",
   "metadata": {},
   "source": [
    "### 11- Ada Boost Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b0bea70f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train_r2': 0.6880360292598227,\n",
       " 'test_r2': 0.5238172057992055,\n",
       " 'train_rmse': np.float64(0.5652555339106106),\n",
       " 'test_rmse': np.float64(0.6530035147104616)}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "\n",
    "ABR: BaseEstimator = AdaBoostRegressor()\n",
    "\n",
    "train_and_evaluate(model= ABR,\n",
    "                   X_train= X_train,\n",
    "                   y_train= y_train,\n",
    "                   X_test= X_test,\n",
    "                   y_test= y_test\n",
    "                   )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "390c831d",
   "metadata": {},
   "source": [
    "### 12- Gradient Boost Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "88558626",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train_r2': 0.8463574105180187,\n",
       " 'test_r2': 0.47880041034185317,\n",
       " 'train_rmse': np.float64(0.3966874054487283),\n",
       " 'test_rmse': np.float64(0.6831730122163806)}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "GBR: BaseEstimator = GradientBoostingRegressor()\n",
    "\n",
    "train_and_evaluate(model= GBR,\n",
    "                   X_train= X_train,\n",
    "                   y_train= y_train,\n",
    "                   X_test= X_test,\n",
    "                   y_test= y_test\n",
    "                   )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b879b2",
   "metadata": {},
   "source": [
    "### 13- XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f828c181",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train_r2': 0.9997686847434863,\n",
       " 'test_r2': 0.36175241234665123,\n",
       " 'train_rmse': np.float64(0.015391988917463547),\n",
       " 'test_rmse': np.float64(0.7560025498102566)}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "\n",
    "XGBR: BaseEstimator = XGBRegressor()\n",
    "\n",
    "train_and_evaluate(model= XGBR,\n",
    "                   X_train= X_train,\n",
    "                   y_train= y_train,\n",
    "                   X_test= X_test,\n",
    "                   y_test= y_test\n",
    "                   )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc8e7d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
