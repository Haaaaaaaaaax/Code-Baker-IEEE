{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38a9c295",
   "metadata": {},
   "source": [
    "# <h1 style=\"text-align:center; color:blue;\">Classification algorithms part 2</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eff4bb67",
   "metadata": {},
   "source": [
    "**We use the same data as part 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "992ec90e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train shape: (447, 5), Test shape: (112, 5)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import numpy.typing as npt\n",
    "import pandas as pd\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "# 1. Generate synthetic classification data\n",
    "X: npt.NDArray[np.float64]\n",
    "y: npt.NDArray[np.int64]\n",
    "X, y = make_classification(\n",
    "    n_samples=1000,\n",
    "    n_features=10,\n",
    "    n_informative=6,\n",
    "    n_redundant=2,\n",
    "    n_classes=2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Convert to DataFrame for easier manipulation\n",
    "feature_names: list[str] = [f\"feature_{i}\" for i in range(X.shape[1])]\n",
    "df: pd.DataFrame = pd.DataFrame(X, columns=feature_names)\n",
    "df['target'] = y\n",
    "\n",
    "# 2. Introduce some NaN values randomly for demonstration\n",
    "rng: np.random.Generator = np.random.default_rng(42)\n",
    "nan_mask: npt.NDArray[np.bool_] = rng.choice([True, False], size=df[feature_names].shape, p=[0.05, 0.95])\n",
    "df.loc[:, feature_names] = df[feature_names].mask(nan_mask)\n",
    "\n",
    "# 3. Drop NaN values\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# 4 Outlier removal (using IQR for numerical columns)\n",
    "def remove_outliers_iqr(data: pd.DataFrame,\n",
    "                        column: str) -> pd.DataFrame:\n",
    "    Q1: float = data[column].quantile(0.25)\n",
    "    Q3: float = data[column].quantile(0.75)\n",
    "    IQR: float = Q3 - Q1\n",
    "    not_outliers: pd.DataFrame = data[(data[column] > (Q1 - 1.5 * IQR)) & (data[column] < (Q3 + 1.5 * IQR))]\n",
    "    return not_outliers\n",
    "\n",
    "outliers_cols: list[str] = feature_names.copy()\n",
    "\n",
    "for col in outliers_cols:\n",
    "    df = remove_outliers_iqr(df, col)\n",
    "\n",
    "# 5. Encoding and Scaling\n",
    "\n",
    "# We will only use Scaling as sklearn created the target encoded internally\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "# We already have the column names\n",
    "numeric_cols: list[str] = feature_names.copy()\n",
    "\n",
    "# Creating object\n",
    "scaler: StandardScaler = StandardScaler()\n",
    "\n",
    "# The template code for Scaling\n",
    "for col in numeric_cols:\n",
    "    df[[col]] = scaler.fit_transform(df[[col]])\n",
    "\n",
    "# Remove weak correlations\n",
    "# See Part 1 to know more\n",
    "\n",
    "weak_corr_cols: list[str] = ['feature_0', 'feature_2', 'feature_3', 'feature_6', 'feature_7']\n",
    "\n",
    "df.drop(weak_corr_cols, axis=1, inplace=True)\n",
    "\n",
    "# 7. Splitting\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the target and features\n",
    "\n",
    "X: pd.DataFrame = df.drop('target', axis=1)\n",
    "y: pd.Series = df['target']\n",
    "\n",
    "X_train: pd.DataFrame\n",
    "X_test: pd.DataFrame\n",
    "y_train: pd.DataFrame\n",
    "y_test: pd.DataFrame\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"\\nTrain shape: {X_train.shape}, Test shape: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52a69be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.base import BaseEstimator\n",
    "from typing import Tuple\n",
    "\n",
    "def evaluate_model(model: BaseEstimator,\n",
    "                   X_train: pd.DataFrame,\n",
    "                   y_train: pd.Series,\n",
    "                   X_test: pd.DataFrame,\n",
    "                   y_test: pd.Series) -> Tuple[str, npt.NDArray[np.int64]]:\n",
    "    \"\"\"\n",
    "    Trains the given model and returns the classification report and confusion matrix for test predictions.\n",
    "\n",
    "    Parameters:\n",
    "        model: The classification model to train.\n",
    "        X_train: Training features.\n",
    "        y_train: Training labels.\n",
    "        X_test: Test features.\n",
    "        y_test: Test labels.\n",
    "\n",
    "    Returns:\n",
    "        report: Classification report as a string.\n",
    "        cm: Confusion matrix as a numpy array.\n",
    "    \"\"\"\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred: npt.NDArray[np.float64] = model.predict(X_test)\n",
    "    report: str = classification_report(y_test, y_pred)\n",
    "    cm: npt.NDArray[np.float64] = confusion_matrix(y_test, y_pred)\n",
    "    return report, cm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aad3e9e",
   "metadata": {},
   "source": [
    "### 4- Support Vector Machines (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4bf0b71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.81      0.80        57\n",
      "           1       0.80      0.78      0.79        55\n",
      "\n",
      "    accuracy                           0.79       112\n",
      "   macro avg       0.79      0.79      0.79       112\n",
      "weighted avg       0.79      0.79      0.79       112\n",
      "\n",
      "\n",
      "Confusion matrix\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[46, 11],\n",
       "       [12, 43]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "linear_svc: BaseEstimator = LinearSVC()\n",
    "\n",
    "report, cm = evaluate_model(model=linear_svc,\n",
    "                            X_train=X_train,\n",
    "                            X_test=X_test,\n",
    "                            y_train=y_train,\n",
    "                            y_test=y_test\n",
    "                            )\n",
    "\n",
    "print(\"\\nClassification report\\n\", report)\n",
    "print(\"\\nConfusion matrix\\n\")\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e40e9f9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.88      0.87        57\n",
      "           1       0.87      0.85      0.86        55\n",
      "\n",
      "    accuracy                           0.87       112\n",
      "   macro avg       0.87      0.87      0.87       112\n",
      "weighted avg       0.87      0.87      0.87       112\n",
      "\n",
      "\n",
      "Confusion matrix\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[50,  7],\n",
       "       [ 8, 47]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svc = SVC()\n",
    "\n",
    "report, cm = evaluate_model(model=svc,\n",
    "                            X_train=X_train,\n",
    "                            X_test=X_test,\n",
    "                            y_train=y_train,\n",
    "                            y_test=y_test\n",
    "                            )\n",
    "\n",
    "print(\"\\nClassification report\\n\", report)\n",
    "print(\"\\nConfusion matrix\\n\")\n",
    "cm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f14eda",
   "metadata": {},
   "source": [
    "### 5- Decision Trees Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04a661b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.88      0.82        57\n",
      "           1       0.85      0.73      0.78        55\n",
      "\n",
      "    accuracy                           0.80       112\n",
      "   macro avg       0.81      0.80      0.80       112\n",
      "weighted avg       0.81      0.80      0.80       112\n",
      "\n",
      "\n",
      "Confusion matrix\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[50,  7],\n",
       "       [15, 40]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "DTC: BaseEstimator = DecisionTreeClassifier()\n",
    "\n",
    "report, cm = evaluate_model(model=DTC,\n",
    "                            X_train=X_train,\n",
    "                            X_test=X_test,\n",
    "                            y_train=y_train,\n",
    "                            y_test=y_test\n",
    "                            )\n",
    "\n",
    "print(\"\\nClassification report\\n\", report)\n",
    "print(\"\\nConfusion matrix\\n\")\n",
    "cm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85dcec07",
   "metadata": {},
   "source": [
    "### 6- Random Forests Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8769c6ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.93      0.88        57\n",
      "           1       0.92      0.80      0.85        55\n",
      "\n",
      "    accuracy                           0.87       112\n",
      "   macro avg       0.87      0.86      0.87       112\n",
      "weighted avg       0.87      0.87      0.87       112\n",
      "\n",
      "\n",
      "Confusion matrix\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[53,  4],\n",
       "       [11, 44]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "RF: BaseEstimator = RandomForestClassifier()\n",
    "\n",
    "report, cm = evaluate_model(model=RF,\n",
    "                            X_train=X_train,\n",
    "                            X_test=X_test,\n",
    "                            y_train=y_train,\n",
    "                            y_test=y_test\n",
    "                            )\n",
    "\n",
    "print(\"\\nClassification report\\n\", report)\n",
    "print(\"\\nConfusion matrix\\n\")\n",
    "cm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3967f9f7",
   "metadata": {},
   "source": [
    "### 7- Naive Bayes Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a551200",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.81      0.83        57\n",
      "           1       0.81      0.85      0.83        55\n",
      "\n",
      "    accuracy                           0.83       112\n",
      "   macro avg       0.83      0.83      0.83       112\n",
      "weighted avg       0.83      0.83      0.83       112\n",
      "\n",
      "\n",
      "Confusion matrix\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[46, 11],\n",
       "       [ 8, 47]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "GNB: BaseEstimator = GaussianNB()\n",
    "\n",
    "report, cm = evaluate_model(model=GNB,\n",
    "                            X_train=X_train,\n",
    "                            X_test=X_test,\n",
    "                            y_train=y_train,\n",
    "                            y_test=y_test\n",
    "                            )\n",
    "\n",
    "print(\"\\nClassification report\\n\", report)\n",
    "print(\"\\nConfusion matrix\\n\")\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4f00ba81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.82      0.84        57\n",
      "           1       0.82      0.85      0.84        55\n",
      "\n",
      "    accuracy                           0.84       112\n",
      "   macro avg       0.84      0.84      0.84       112\n",
      "weighted avg       0.84      0.84      0.84       112\n",
      "\n",
      "\n",
      "Confusion matrix\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[47, 10],\n",
       "       [ 8, 47]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "BNB: BaseEstimator = BernoulliNB()\n",
    "\n",
    "report, cm = evaluate_model(model=BNB,\n",
    "                            X_train=X_train,\n",
    "                            X_test=X_test,\n",
    "                            y_train=y_train,\n",
    "                            y_test=y_test\n",
    "                            )\n",
    "\n",
    "print(\"\\nClassification report\\n\", report)\n",
    "print(\"\\nConfusion matrix\\n\")\n",
    "cm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1641265",
   "metadata": {},
   "source": [
    "### Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf8fb583",
   "metadata": {},
   "source": [
    "### 8- AdaBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c4c96bb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.84      0.83        57\n",
      "           1       0.83      0.82      0.83        55\n",
      "\n",
      "    accuracy                           0.83       112\n",
      "   macro avg       0.83      0.83      0.83       112\n",
      "weighted avg       0.83      0.83      0.83       112\n",
      "\n",
      "\n",
      "Confusion matrix\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[48,  9],\n",
       "       [10, 45]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "ABC: BaseEstimator = AdaBoostClassifier()\n",
    "\n",
    "report, cm = evaluate_model(model=ABC,\n",
    "                            X_train=X_train,\n",
    "                            X_test=X_test,\n",
    "                            y_train=y_train,\n",
    "                            y_test=y_test\n",
    "                            )\n",
    "\n",
    "print(\"\\nClassification report\\n\", report)\n",
    "print(\"\\nConfusion matrix\\n\")\n",
    "cm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c21bfa54",
   "metadata": {},
   "source": [
    "### 9- Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a80cc0e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.91      0.85        57\n",
      "           1       0.89      0.76      0.82        55\n",
      "\n",
      "    accuracy                           0.84       112\n",
      "   macro avg       0.85      0.84      0.84       112\n",
      "weighted avg       0.85      0.84      0.84       112\n",
      "\n",
      "\n",
      "Confusion matrix\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[52,  5],\n",
       "       [13, 42]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "GBC: BaseEstimator = GradientBoostingClassifier()\n",
    "\n",
    "report, cm = evaluate_model(model=GBC,\n",
    "                            X_train=X_train,\n",
    "                            X_test=X_test,\n",
    "                            y_train=y_train,\n",
    "                            y_test=y_test\n",
    "                            )\n",
    "\n",
    "print(\"\\nClassification report\\n\", report)\n",
    "print(\"\\nConfusion matrix\\n\")\n",
    "cm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92556704",
   "metadata": {},
   "source": [
    "### 10- XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7a3c33ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.93      0.88        57\n",
      "           1       0.92      0.80      0.85        55\n",
      "\n",
      "    accuracy                           0.87       112\n",
      "   macro avg       0.87      0.86      0.87       112\n",
      "weighted avg       0.87      0.87      0.87       112\n",
      "\n",
      "\n",
      "Confusion matrix\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[53,  4],\n",
       "       [11, 44]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "XGBC: BaseEstimator = XGBClassifier()\n",
    "\n",
    "report, cm = evaluate_model(model=XGBC,\n",
    "                            X_train=X_train,\n",
    "                            X_test=X_test,\n",
    "                            y_train=y_train,\n",
    "                            y_test=y_test\n",
    "                            )\n",
    "\n",
    "print(\"\\nClassification report\\n\", report)\n",
    "print(\"\\nConfusion matrix\\n\")\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb861503",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
